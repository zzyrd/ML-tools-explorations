{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Name: Zhihao Zhang\n",
    "# NetID: zz2432\n",
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from scipy.sparse import csr_matrix\n",
    "from cvxopt import matrix, solvers\n",
    "solvers.options['show_progress'] = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### My impelmentation of Gaussian Kernel on SVM\n",
    "\n",
    "Instead of linear kernel we implemented in class. We modified Kernel function to Gaussian_kernel, where xi is the data point, xj is the landmark. Here we assume the landmark l1 = x1, l2 = x2, ...ln = xn.\n",
    "\n",
    "Because of use of Gaussian kernel, we need to pick sigma parameter. In the kernel_svm function, everything else is the same as we did in the homework except for computing x.T.x. term. We loop through all the datapoints then loop through all the landmarks, calculate the gaussian between them and assign it back. \n",
    "\n",
    "compute_classification_boundary is the same in the homework, which return w and w0 for us.\n",
    "\n",
    "In f_dual function, instead of finding support vectors based on alphas, we directly use w and w0 to decide our prediction for a given datapoints."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Gaussian_Kernel(xi, xj, sigma):\n",
    "    return np.exp(-(xi-xj).T.dot(xi-xj) / (2*sigma**2))\n",
    "\n",
    "def kernel_svm(X, y, sigma=1): \n",
    "    N = y.size\n",
    "    yy = y.reshape((N,1)).dot(y.reshape((1,N)))\n",
    "    # use gaussian kernel\n",
    "    xTx = np.zeros((N, N))\n",
    "    for i in range(N):\n",
    "        for j in range(N):\n",
    "            xTx[i,j] = Gaussian_Kernel(X[i], X[j], sigma)\n",
    "    \n",
    "    P = matrix(xTx * yy, tc='d')\n",
    "    q = matrix(np.ones(N)*-1,tc='d')    \n",
    "    G = matrix(np.eye(N)*-1, tc='d')\n",
    "    h = matrix(np.zeros(N),tc='d')\n",
    "    A = matrix(y.reshape((1,N)),tc='d')\n",
    "    b = matrix(0,tc='d')\n",
    "    \n",
    "    sol = solvers.qp(P,q,G,h,A,b)\n",
    "    alphas = sol['x']\n",
    "    \n",
    "    for i in range(len(alphas)):\n",
    "        if alphas[i] <= (1/1000):\n",
    "            alphas[i] = 0\n",
    "\n",
    "    return alphas\n",
    "\n",
    "def compute_classification_boundary (X, y, alphas):\n",
    "    # find indices where a != 0, we only need to consider these points\n",
    "    I = np.where(np.array(alphas) != 0)[0]\n",
    "    w = np.zeros(X.shape[1])\n",
    "    for i in I:\n",
    "        w += np.array(alphas)[i]*y[i]*X[i]\n",
    "    # choose one support vector to calculate w0\n",
    "    k = I[0]\n",
    "    w0 = y[k] - X[k].dot(w)\n",
    "    return w, w0\n",
    "\n",
    "def f_dual(X,w,w0):    \n",
    "    f = X.dot(w)+w0\n",
    "    f[np.where(f>0)] = 1\n",
    "    f[np.where(f<0)] = -1\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Dataset used in class: breast_cancer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_breast_cancer\n",
    "data = load_breast_cancer()\n",
    "X = data.data\n",
    "y = data.target\n",
    "X_train_tmp, X_test_tmp, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "# set training label y=0 to y=-1\n",
    "y_train[np.where(y_train==0)] = -1\n",
    "y_test[np.where(y_test==0)] = -1\n",
    "# scale the data since we need to compute distance by Gaussian kernel\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_tmp)\n",
    "X_train = scaler.transform(X_train_tmp)\n",
    "X_test = scaler.transform(X_test_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 781 ms, sys: 14.1 ms, total: 795 ms\n",
      "Wall time: 720 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alphas = kernel_svm(X_train,y_train,sigma=4)\n",
    "w, w0= compute_classification_boundary(X_train,y_train,alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on running gaussian kernel using SVM: 0.9883040935672515\n"
     ]
    }
   ],
   "source": [
    "preds = f_dual(X_test, w, w0)\n",
    "res = np.where(y_test == preds)[0].size / y_test.size\n",
    "print(f'Accuracy on running gaussian kernel using SVM: {res}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Dataset outside class:  fetch_20newsgroups_vectorized\n",
    "Dataset that contains lots of features for a single sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups_vectorized\n",
    "data = fetch_20newsgroups_vectorized()\n",
    "\n",
    "# do binary classification: only select two classes.\n",
    "# idx for label 18 and label 19\n",
    "idx = np.where(data.target>=18)\n",
    "X = data.data[idx]\n",
    "y = data.target[idx]\n",
    "X_train_tmp, X_test_tmp, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# set training label y=18 to y=-1\n",
    "y_train[np.where(y_train==18)] = -1\n",
    "y_test[np.where(y_test==18)] = -1\n",
    "# set training label y=19 to y=1\n",
    "y_train[np.where(y_train==19)] = 1\n",
    "y_test[np.where(y_test==19)] = 1\n",
    "\n",
    "\n",
    "# convert sparse matrix back to numpy matrix\n",
    "X_train_tmp = csr_matrix.toarray(X_train_tmp)\n",
    "X_test_tmp = csr_matrix.toarray(X_test_tmp)\n",
    "# scale the data since we need to compute distance by Gaussian kernel\n",
    "scaler = preprocessing.StandardScaler().fit(X_train_tmp)\n",
    "X_train = scaler.transform(X_train_tmp)\n",
    "X_test = scaler.transform(X_test_tmp)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Run our implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6min 20s, sys: 52.1 s, total: 7min 12s\n",
      "Wall time: 1min 13s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "alphas = kernel_svm(X_train,y_train,sigma=1)\n",
    "w, w0= compute_classification_boundary(X_train,y_train,alphas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy on running gaussian kernel using SVM: 0.9407114624505929\n"
     ]
    }
   ],
   "source": [
    "preds = f_dual(X_test, w, w0)\n",
    "res = np.where(y_test == preds)[0].size / y_test.size\n",
    "print(f'Accuracy on running gaussian kernel using SVM: {res}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
